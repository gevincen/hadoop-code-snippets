2017-03-11 22:04:10  [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2017-03-11 22:04:10  [ main:10 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-03-11 22:04:11  [ main:527 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-03-11 22:04:11  [ main:531 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-03-11 22:04:11  [ main:561 ] - [ INFO ]  Total input paths to process : 1
2017-03-11 22:04:11  [ main:641 ] - [ INFO ]  number of splits:1
2017-03-11 22:04:11  [ main:859 ] - [ INFO ]  Submitting tokens for job: job_local1227121236_0001
2017-03-11 22:04:12  [ main:1237 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2017-03-11 22:04:12  [ main:1238 ] - [ INFO ]  Running job: job_local1227121236_0001
2017-03-11 22:04:12  [ Thread-3:1249 ] - [ INFO ]  OutputCommitter set in config null
2017-03-11 22:04:12  [ Thread-3:1269 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-03-11 22:04:12  [ Thread-3:1410 ] - [ INFO ]  Waiting for map tasks
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1422 ] - [ INFO ]  Starting task: attempt_local1227121236_0001_m_000000_0
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1488 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1648 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@748eac13
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1654 ] - [ INFO ]  Processing split: hdfs://192.168.1.112:9000/wxm/input/read.txt:0+387
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1700 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1700 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1700 ] - [ INFO ]  soft limit at 83886080
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1700 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1700 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1703 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1811 ] - [ INFO ]  
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1813 ] - [ INFO ]  Starting flush of map output
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1813 ] - [ INFO ]  Spilling map output
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1814 ] - [ INFO ]  bufstart = 0; bufend = 525; bufvoid = 104857600
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1814 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1831 ] - [ INFO ]  Finished spill 0
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1841 ] - [ INFO ]  Task:attempt_local1227121236_0001_m_000000_0 is done. And is in the process of committing
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1855 ] - [ INFO ]  map
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1855 ] - [ INFO ]  Task 'attempt_local1227121236_0001_m_000000_0' done.
2017-03-11 22:04:12  [ LocalJobRunner Map Task Executor #0:1855 ] - [ INFO ]  Finishing task: attempt_local1227121236_0001_m_000000_0
2017-03-11 22:04:12  [ Thread-3:1856 ] - [ INFO ]  map task executor complete.
2017-03-11 22:04:12  [ Thread-3:1858 ] - [ INFO ]  Waiting for reduce tasks
2017-03-11 22:04:12  [ pool-6-thread-1:1858 ] - [ INFO ]  Starting task: attempt_local1227121236_0001_r_000000_0
2017-03-11 22:04:12  [ pool-6-thread-1:1867 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2017-03-11 22:04:12  [ pool-6-thread-1:1958 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@23873c1e
2017-03-11 22:04:12  [ pool-6-thread-1:1962 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67d2110a
2017-03-11 22:04:12  [ pool-6-thread-1:1976 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-03-11 22:04:12  [ EventFetcher for fetching Map Completion Events:1979 ] - [ INFO ]  attempt_local1227121236_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-03-11 22:04:13  [ localfetcher#1:2031 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1227121236_0001_m_000000_0 decomp: 597 len: 601 to MEMORY
2017-03-11 22:04:13  [ localfetcher#1:2036 ] - [ INFO ]  Read 597 bytes from map-output for attempt_local1227121236_0001_m_000000_0
2017-03-11 22:04:13  [ localfetcher#1:2039 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 597, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->597
2017-03-11 22:04:13  [ EventFetcher for fetching Map Completion Events:2040 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2017-03-11 22:04:13  [ pool-6-thread-1:2041 ] - [ INFO ]  1 / 1 copied.
2017-03-11 22:04:13  [ pool-6-thread-1:2042 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-03-11 22:04:13  [ pool-6-thread-1:2052 ] - [ INFO ]  Merging 1 sorted segments
2017-03-11 22:04:13  [ pool-6-thread-1:2053 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 584 bytes
2017-03-11 22:04:13  [ pool-6-thread-1:2056 ] - [ INFO ]  Merged 1 segments, 597 bytes to disk to satisfy reduce memory limit
2017-03-11 22:04:13  [ pool-6-thread-1:2057 ] - [ INFO ]  Merging 1 files, 601 bytes from disk
2017-03-11 22:04:13  [ pool-6-thread-1:2058 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2017-03-11 22:04:13  [ pool-6-thread-1:2058 ] - [ INFO ]  Merging 1 sorted segments
2017-03-11 22:04:13  [ pool-6-thread-1:2059 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 584 bytes
2017-03-11 22:04:13  [ pool-6-thread-1:2059 ] - [ INFO ]  1 / 1 copied.
2017-03-11 22:04:13  [ pool-6-thread-1:2092 ] - [ WARN ]  Failed to load/initialize native-zlib library
2017-03-11 22:04:13  [ pool-6-thread-1:2094 ] - [ INFO ]  Got brand-new compressor [.deflate]
2017-03-11 22:04:13  [ pool-6-thread-1:2100 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-03-11 22:04:13  [ pool-6-thread-1:2238 ] - [ INFO ]  Task:attempt_local1227121236_0001_r_000000_0 is done. And is in the process of committing
2017-03-11 22:04:13  [ main:2246 ] - [ INFO ]  Job job_local1227121236_0001 running in uber mode : false
2017-03-11 22:04:13  [ pool-6-thread-1:2246 ] - [ INFO ]  1 / 1 copied.
2017-03-11 22:04:13  [ pool-6-thread-1:2247 ] - [ INFO ]  Task attempt_local1227121236_0001_r_000000_0 is allowed to commit now
2017-03-11 22:04:13  [ main:2249 ] - [ INFO ]   map 100% reduce 0%
2017-03-11 22:04:13  [ pool-6-thread-1:2259 ] - [ INFO ]  Saved output of task 'attempt_local1227121236_0001_r_000000_0' to hdfs://192.168.1.112:9000/wxm/output/write.txt/_temporary/0/task_local1227121236_0001_r_000000
2017-03-11 22:04:13  [ pool-6-thread-1:2260 ] - [ INFO ]  reduce > reduce
2017-03-11 22:04:13  [ pool-6-thread-1:2261 ] - [ INFO ]  Task 'attempt_local1227121236_0001_r_000000_0' done.
2017-03-11 22:04:13  [ pool-6-thread-1:2261 ] - [ INFO ]  Finishing task: attempt_local1227121236_0001_r_000000_0
2017-03-11 22:04:13  [ Thread-3:2261 ] - [ INFO ]  reduce task executor complete.
2017-03-11 22:04:14  [ main:3250 ] - [ INFO ]   map 100% reduce 100%
2017-03-11 22:04:14  [ main:3252 ] - [ INFO ]  Job job_local1227121236_0001 completed successfully
2017-03-11 22:04:14  [ main:3282 ] - [ INFO ]  Counters: 38
	File System Counters
		FILE: Number of bytes read=1558
		FILE: Number of bytes written=519515
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=774
		HDFS: Number of bytes written=202
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=23
		Map output records=35
		Map output bytes=525
		Map output materialized bytes=601
		Input split bytes=109
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=601
		Reduce input records=35
		Reduce output records=1
		Spilled Records=70
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=505413632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=387
	File Output Format Counters 
		Bytes Written=202
2017-03-11 22:07:59  [ main:1 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id
2017-03-11 22:07:59  [ main:5 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-03-11 22:08:00  [ main:541 ] - [ WARN ]  Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2017-03-11 22:08:00  [ main:543 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2017-03-11 22:08:00  [ main:576 ] - [ INFO ]  Total input paths to process : 1
2017-03-11 22:08:00  [ main:651 ] - [ INFO ]  number of splits:1
2017-03-11 22:08:00  [ main:792 ] - [ INFO ]  Submitting tokens for job: job_local885385052_0001
2017-03-11 22:08:01  [ main:1156 ] - [ INFO ]  The url to track the job: http://localhost:8080/
2017-03-11 22:08:01  [ main:1157 ] - [ INFO ]  Running job: job_local885385052_0001
2017-03-11 22:08:01  [ Thread-3:1173 ] - [ INFO ]  OutputCommitter set in config null
2017-03-11 22:08:01  [ Thread-3:1192 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2017-03-11 22:08:01  [ Thread-3:1305 ] - [ INFO ]  Waiting for map tasks
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1315 ] - [ INFO ]  Starting task: attempt_local885385052_0001_m_000000_0
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1667 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7f8a3226
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1674 ] - [ INFO ]  Processing split: hdfs://192.168.1.112:9000/wxm/input/read.txt:0+387
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1745 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584)
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1746 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1746 ] - [ INFO ]  soft limit at 83886080
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1746 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1746 ] - [ INFO ]  kvstart = 26214396; length = 6553600
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1750 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1895 ] - [ INFO ]  
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1898 ] - [ INFO ]  Starting flush of map output
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1898 ] - [ INFO ]  Spilling map output
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1898 ] - [ INFO ]  bufstart = 0; bufend = 525; bufvoid = 104857600
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1899 ] - [ INFO ]  kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1917 ] - [ INFO ]  Finished spill 0
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1931 ] - [ INFO ]  Task:attempt_local885385052_0001_m_000000_0 is done. And is in the process of committing
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1959 ] - [ INFO ]  map
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1960 ] - [ INFO ]  Task 'attempt_local885385052_0001_m_000000_0' done.
2017-03-11 22:08:01  [ LocalJobRunner Map Task Executor #0:1961 ] - [ INFO ]  Finishing task: attempt_local885385052_0001_m_000000_0
2017-03-11 22:08:01  [ Thread-3:1962 ] - [ INFO ]  map task executor complete.
2017-03-11 22:08:01  [ Thread-3:1966 ] - [ INFO ]  Waiting for reduce tasks
2017-03-11 22:08:01  [ pool-6-thread-1:1967 ] - [ INFO ]  Starting task: attempt_local885385052_0001_r_000000_0
2017-03-11 22:08:01  [ pool-6-thread-1:1976 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux.
2017-03-11 22:08:01  [ pool-6-thread-1:2103 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@9d5f7e1
2017-03-11 22:08:01  [ pool-6-thread-1:2108 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7ce29e79
2017-03-11 22:08:02  [ pool-6-thread-1:2129 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2017-03-11 22:08:02  [ EventFetcher for fetching Map Completion Events:2135 ] - [ INFO ]  attempt_local885385052_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2017-03-11 22:08:02  [ main:2170 ] - [ INFO ]  Job job_local885385052_0001 running in uber mode : false
2017-03-11 22:08:02  [ main:2185 ] - [ INFO ]   map 100% reduce 0%
2017-03-11 22:08:02  [ localfetcher#1:2212 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local885385052_0001_m_000000_0 decomp: 597 len: 601 to MEMORY
2017-03-11 22:08:02  [ localfetcher#1:2221 ] - [ INFO ]  Read 597 bytes from map-output for attempt_local885385052_0001_m_000000_0
2017-03-11 22:08:02  [ localfetcher#1:2228 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 597, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->597
2017-03-11 22:08:02  [ EventFetcher for fetching Map Completion Events:2230 ] - [ INFO ]  EventFetcher is interrupted.. Returning
2017-03-11 22:08:02  [ pool-6-thread-1:2232 ] - [ INFO ]  1 / 1 copied.
2017-03-11 22:08:02  [ pool-6-thread-1:2232 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2017-03-11 22:08:02  [ pool-6-thread-1:2248 ] - [ INFO ]  Merging 1 sorted segments
2017-03-11 22:08:02  [ pool-6-thread-1:2249 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 584 bytes
2017-03-11 22:08:02  [ pool-6-thread-1:2253 ] - [ INFO ]  Merged 1 segments, 597 bytes to disk to satisfy reduce memory limit
2017-03-11 22:08:02  [ pool-6-thread-1:2254 ] - [ INFO ]  Merging 1 files, 601 bytes from disk
2017-03-11 22:08:02  [ pool-6-thread-1:2255 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce
2017-03-11 22:08:02  [ pool-6-thread-1:2255 ] - [ INFO ]  Merging 1 sorted segments
2017-03-11 22:08:02  [ pool-6-thread-1:2258 ] - [ INFO ]  Down to the last merge-pass, with 1 segments left of total size: 584 bytes
2017-03-11 22:08:02  [ pool-6-thread-1:2259 ] - [ INFO ]  1 / 1 copied.
2017-03-11 22:08:02  [ pool-6-thread-1:2328 ] - [ WARN ]  Failed to load/initialize native-zlib library
2017-03-11 22:08:02  [ pool-6-thread-1:2330 ] - [ INFO ]  Got brand-new compressor [.deflate]
2017-03-11 22:08:02  [ pool-6-thread-1:2345 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2017-03-11 22:08:02  [ pool-6-thread-1:2559 ] - [ INFO ]  Task:attempt_local885385052_0001_r_000000_0 is done. And is in the process of committing
2017-03-11 22:08:02  [ pool-6-thread-1:2569 ] - [ INFO ]  1 / 1 copied.
2017-03-11 22:08:02  [ pool-6-thread-1:2570 ] - [ INFO ]  Task attempt_local885385052_0001_r_000000_0 is allowed to commit now
2017-03-11 22:08:02  [ pool-6-thread-1:2633 ] - [ INFO ]  Saved output of task 'attempt_local885385052_0001_r_000000_0' to hdfs://192.168.1.112:9000/wxm/output/write/_temporary/0/task_local885385052_0001_r_000000
2017-03-11 22:08:02  [ pool-6-thread-1:2635 ] - [ INFO ]  reduce > reduce
2017-03-11 22:08:02  [ pool-6-thread-1:2635 ] - [ INFO ]  Task 'attempt_local885385052_0001_r_000000_0' done.
2017-03-11 22:08:02  [ pool-6-thread-1:2635 ] - [ INFO ]  Finishing task: attempt_local885385052_0001_r_000000_0
2017-03-11 22:08:02  [ Thread-3:2636 ] - [ INFO ]  reduce task executor complete.
2017-03-11 22:08:03  [ main:3186 ] - [ INFO ]   map 100% reduce 100%
2017-03-11 22:08:03  [ main:3188 ] - [ INFO ]  Job job_local885385052_0001 completed successfully
2017-03-11 22:08:03  [ main:3236 ] - [ INFO ]  Counters: 38
	File System Counters
		FILE: Number of bytes read=1558
		FILE: Number of bytes written=516811
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=774
		HDFS: Number of bytes written=202
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=23
		Map output records=35
		Map output bytes=525
		Map output materialized bytes=601
		Input split bytes=109
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=601
		Reduce input records=35
		Reduce output records=1
		Spilled Records=70
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=501219328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=387
	File Output Format Counters 
		Bytes Written=202
2017-03-11 22:09:44  [ main:0 ] - [ WARN ]  Failed to load/initialize native-zlib library
2017-03-11 22:09:44  [ main:6 ] - [ INFO ]  Got brand-new decompressor [.deflate]
2017-03-11 22:09:44  [ main:16 ] - [ INFO ]  Got brand-new decompressor [.deflate]
2017-03-11 22:09:44  [ main:16 ] - [ INFO ]  Got brand-new decompressor [.deflate]
2017-03-11 22:09:44  [ main:16 ] - [ INFO ]  Got brand-new decompressor [.deflate]
2017-03-11 22:50:37  [ main:0 ] - [ WARN ]  Failed to load/initialize native-zlib library
2017-03-11 22:50:37  [ main:7 ] - [ INFO ]  Got brand-new decompressor [.deflate]
2017-03-11 22:50:37  [ main:18 ] - [ INFO ]  Got brand-new decompressor [.deflate]
2017-03-11 22:50:37  [ main:18 ] - [ INFO ]  Got brand-new decompressor [.deflate]
2017-03-11 22:50:37  [ main:19 ] - [ INFO ]  Got brand-new decompressor [.deflate]
2017-03-11 22:51:03  [ main:0 ] - [ WARN ]  Failed to load/initialize native-zlib library
2017-03-11 22:51:03  [ main:7 ] - [ INFO ]  Got brand-new decompressor [.deflate]
2017-03-11 22:54:05  [ main:0 ] - [ WARN ]  Failed to load/initialize native-zlib library
2017-03-11 22:54:05  [ main:15 ] - [ INFO ]  Got brand-new decompressor [.deflate]
2017-03-11 22:56:44  [ main:0 ] - [ WARN ]  Failed to load/initialize native-zlib library
2017-03-11 22:56:44  [ main:19 ] - [ INFO ]  Got brand-new decompressor [.deflate]
